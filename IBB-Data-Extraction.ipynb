{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Are you on PC or MAC? pc = 0, mac = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "computer = 0\n",
    "#! source activate tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Let's fetch the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import numpy as np\n",
    "import pandas_datareader.data as web\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import glob as glob\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "matplotlib.rcParams[ 'figure.figsize' ] = ( 14, 6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROOTPATH = os.getcwd()\n",
    "path = os.path.join(ROOTPATH, 'Data')\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In the file IBB_holdings.csv, the tickers are sorted by descending weigths as of 5-Feb-18\n",
    "# The file contains a lot of information about the fund IBB as of 5-Feb-18, which can be imported via row[i], i being the column you want\n",
    "# For now we only import the first column, tickers.\n",
    "\n",
    "if computer == 0:\n",
    "    with open('IBB_holdings.csv', 'r') as csvfile:\n",
    "        file = csv.reader(csvfile, delimiter=' ')\n",
    "        c=0\n",
    "        list_tickers=[]\n",
    "        for row in file:\n",
    "            if c >= 11:\n",
    "                list_tickers.append(row[0].split(',')[0])\n",
    "            c+=1\n",
    "else:\n",
    "    with open('IBB_holdings.csv', 'r', encoding ='mac_roman') as csvfile:\n",
    "        file = csv.reader(csvfile, delimiter=' ')\n",
    "        c=0\n",
    "        list_tickers=[]\n",
    "        for row in file:\n",
    "            if c >= 11:\n",
    "                list_tickers.append(row[0].split(',')[0])\n",
    "            c+=1\n",
    "            \n",
    "list_tickers.sort()\n",
    "list_tickers.pop()\n",
    "list_tickers.remove(\"BLKFDS\")\n",
    "list_tickers.remove(\"USD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) We now want to download the data of all tickers as dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting up the variables\n",
    "\n",
    "start_date = '2015-05-05'\n",
    "end_date = '2018-01-01'\n",
    "\n",
    "\n",
    "nb_tickers = len(list_tickers)\n",
    "list_dataframes=[None]*(nb_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#On Yahoo\n",
    "still_missing = nb_tickers\n",
    "passages = 0\n",
    "\n",
    "while still_missing > 0 and passages < 100:\n",
    "    passages += 1\n",
    "    print(\"harvest number \" , passages)\n",
    "    for i in range (nb_tickers ):\n",
    "        if type(list_dataframes[i]) == type(None):   \n",
    "            symbol = list_tickers[i]\n",
    "            try:\n",
    "                df = web.DataReader(symbol, 'yahoo' , start_date ,end_date)\n",
    "                list_dataframes[i] = df\n",
    "                still_missing -= 1\n",
    "            except:\n",
    "                print(\"Oops!  That was no valid ticker.  Try again... \"+list_tickers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Finally, we can download in a new folder all this information for future use, to avoid downloading them from the web again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Download of the dataframes as as many csv's (for now)\n",
    "\n",
    "for i in range (nb_tickers ):  \n",
    "    file_name = 'csv_' + list_tickers[i] + '_from_' + start_date + '_to_' + end_date + \".csv\"\n",
    "    string = path + '\\\\' + file_name\n",
    "    list_dataframes[i].to_csv(string , sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) We also need a benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here the benchmark is NASDAQ Biotechnology index \n",
    "symbol='^NBI'\n",
    "benchmark1 = web.DataReader(symbol, 'yahoo' , start_date ,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here the benchmark is iShares Nasdaq Biotechnology ETF \n",
    "symbol='IBB'\n",
    "benchmark2 = web.DataReader(symbol, 'yahoo' , start_date ,end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Now we need rate of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ror_1 = benchmark1['High'].pct_change()\n",
    "df_ror_2 = benchmark2['High'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Both benchmarks should have similar rate of returns, though they have different prices\n",
    "plt.plot(df_ror_1)\n",
    "plt.hold\n",
    "plt.plot(df_ror_2)\n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Create all the new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "allFiles = glob.glob(path + \"/csv\" + \"*.csv\")\n",
    "\n",
    "\n",
    "i=0\n",
    "if computer == 0:\n",
    "    for file_ in allFiles:\n",
    "        with open(file_, 'r') as csvfile:\n",
    "            if list_tickers[i] != 'SNDX':\n",
    "                df = pd.read_csv(csvfile, index_col=None, header=0)\n",
    "            i=i+1\n",
    "    \n",
    "if computer == 1:    \n",
    "    for file_ in allFiles:\n",
    "        with open(file_, 'r', encoding ='mac_roman') as csvfile:\n",
    "            if list_tickers[i] != 'SNDX':\n",
    "                df = pd.read_csv(csvfile, index_col=None, header=0)\n",
    "            i=i+1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
